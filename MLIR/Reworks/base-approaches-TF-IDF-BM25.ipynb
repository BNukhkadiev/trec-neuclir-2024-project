{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from rank_bm25 import BM25Okapi\n",
    "from ir_measures import nDCG, MAP, RBP, Recall, Qrel, ScoredDoc, calc_aggregate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/multi-subset.pkl', 'rb') as file:\n",
    "    multi_subset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ir_datasets.load(\"neuclir/1/multi/trec-2023\")\n",
    "qrels = [(qrel.query_id, qrel.doc_id, qrel.relevance, qrel.iteration) for qrel in dataset.qrels_iter()]\n",
    "\n",
    "df_qrels = pd.DataFrame(\n",
    "    qrels, \n",
    "    columns=[\n",
    "        'query_id', \n",
    "        'doc_id', \n",
    "        'relevance', \n",
    "        'iteration'\n",
    "    ]\n",
    ")\n",
    "\n",
    "english_queries = [\n",
    "    (\n",
    "        query.query_id, \n",
    "        query.title, \n",
    "        query.description, \n",
    "        query.fa_mt_title, \n",
    "        query.fa_mt_description, \n",
    "        query.ru_mt_title, \n",
    "        query.ru_mt_description, \n",
    "        query.zh_mt_title, \n",
    "        query.zh_mt_description, \n",
    "    ) \n",
    "    for query in dataset.queries_iter()\n",
    "]\n",
    "\n",
    "df_queries = pd.DataFrame(\n",
    "    english_queries, \n",
    "    columns=[\n",
    "        'query_id', \n",
    "        'title', \n",
    "        'description', \n",
    "        'fa_mt_title', \n",
    "        'fa_mt_description', \n",
    "        'ru_mt_title', \n",
    "        'ru_mt_description', \n",
    "        'zh_mt_title', \n",
    "        'zh_mt_description', \n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "df_documents = pd.DataFrame(multi_subset, columns=[\"id\", \"title\", \"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(qrels, result):\n",
    "    qrels = [\n",
    "        Qrel(query_id=query_id, doc_id=doc_id, relevance=relevance)\n",
    "        for query_id, doc_id, relevance, _ in qrels   \n",
    "    ]\n",
    "\n",
    "    runs = [\n",
    "        ScoredDoc(query_id=query_id, doc_id=doc_id, score=score)\n",
    "        for query_id, doc_id, score in result\n",
    "    ]\n",
    "    scores = calc_aggregate([nDCG@20, MAP, RBP(rel=1), Recall@100, Recall@1000], qrels, runs)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge qrels with documents to get corresponding title \n",
    "df_merged = pd.merge(df_qrels, df_documents, how='left', left_on='doc_id', right_on='id')\n",
    "\n",
    "df_merged.rename(columns={'title': 'document_title'}, inplace=True)\n",
    "\n",
    "# Extract \n",
    "def get_mt_title(row):\n",
    "    if row['iteration'] == 'fas':\n",
    "        return row['fa_mt_title']\n",
    "    elif row['iteration'] == 'rus':\n",
    "        return row['ru_mt_title']\n",
    "    elif row['iteration'] == 'zho':\n",
    "        return row['zh_mt_title']\n",
    "    else:\n",
    "        return None  \n",
    "\n",
    "# Apply the function to create a new column with the concatenated title\n",
    "df_merged['query_title_translated'] = df_merged.apply(get_mt_title, axis=1)\n",
    "\n",
    "# Optionally, drop unnecessary columns like fa_mt_title, ru_mt_title, zh_mt_title if you no longer need them\n",
    "df_merged.drop(columns=['fa_mt_title', 'ru_mt_title', 'zh_mt_title', 'fa_mt_description', 'ru_mt_description', 'zh_mt_description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25(df_merged): \n",
    "\n",
    "    grouped = df_merged.groupby(\"query_id\")\n",
    "\n",
    "    # For each query, apply BM25\n",
    "    results = []\n",
    "    for query_id, group in tqdm(grouped):\n",
    "        query_title = group[\"query_title_translated\"].iloc[0] \n",
    "        docs_title = group[\"document_title\"].tolist()  \n",
    "        docs_content = group[\"content\"].tolist()  \n",
    "        \n",
    "        # Preprocess titles and content\n",
    "        query_tokens = preprocess(query_title)\n",
    "        doc_title_tokens = [preprocess(doc) for doc in docs_title]\n",
    "        doc_content_tokens = [preprocess(doc) for doc in docs_content]\n",
    "        \n",
    "        # BM25 calculation for document titles\n",
    "        bm25_title = BM25Okapi(doc_title_tokens)\n",
    "        scores_title = bm25_title.get_scores(query_tokens)\n",
    "        \n",
    "        # BM25 calculation for document content\n",
    "        bm25_content = BM25Okapi(doc_content_tokens)\n",
    "        scores_content = bm25_content.get_scores(query_tokens)\n",
    "        \n",
    "        # Calculate BM25 for concatenated title and content\n",
    "        docs_title_and_content = [title + \" \" + content for title, content in zip(docs_title, docs_content)]\n",
    "        doc_title_and_content_tokens = [preprocess(doc) for doc in docs_title_and_content]\n",
    "        bm25_title_and_content = BM25Okapi(doc_title_and_content_tokens)\n",
    "        scores_title_and_content = bm25_title_and_content.get_scores(query_tokens)\n",
    "        \n",
    "        # Append results for each document\n",
    "        for doc_id, score_title, score_content, score_title_and_content, doc_title in zip(group[\"doc_id\"], scores_title, scores_content, scores_title_and_content, docs_title):\n",
    "            results.append({\n",
    "                \"query_id\": query_id,\n",
    "                \"doc_id\": doc_id,\n",
    "                \"document_title\": doc_title,\n",
    "                \"score_title\": score_title,\n",
    "                \"score_content\": score_content,\n",
    "                \"score_title_and_content\": score_title_and_content\n",
    "            })\n",
    "\n",
    "    # Create DataFrame with BM25 scores\n",
    "    bm25_results = pd.DataFrame(results)\n",
    "\n",
    "    # Merge BM25 results with original dataframe\n",
    "    final_df = pd.merge(df_merged, bm25_results, on=[\"query_id\", \"doc_id\"])\n",
    "\n",
    "    # Sort documents within each query by bm25_score inside a query\n",
    "    sorted_final_df = final_df.sort_values(by=[\"query_id\", \"score_title\"], ascending=[True, False])\n",
    "\n",
    "    return sorted_final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6058a679c3c140d0bf8c3efae0fbcf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bm25_df = bm25(df_merged)\n",
    "\n",
    "bm25_runs_title = sorted(zip(bm25_df['query_id'], bm25_df['doc_id'], bm25_df['score_title']), key=lambda x: (x[0], -x[2]))\n",
    "bm25_runs_content = sorted(zip(bm25_df['query_id'], bm25_df['doc_id'], bm25_df['score_content']), key=lambda x: (x[0], -x[2]))\n",
    "bm25_runs_title_and_content= sorted(zip(bm25_df['query_id'], bm25_df['doc_id'], bm25_df['score_title_and_content']), key=lambda x: (x[0], -x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{R@100: 0.14563090791393538,\n",
       " nDCG@20: 0.19282047568519042,\n",
       " RBP(rel=1): 0.2674535363370284,\n",
       " AP: 0.22238520862678107,\n",
       " R@1000: 0.879572641565378}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(qrels, bm25_runs_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{R@100: 0.18155917029250382,\n",
       " nDCG@20: 0.233174007671653,\n",
       " RBP(rel=1): 0.34040014205674474,\n",
       " AP: 0.2544200727112165,\n",
       " R@1000: 0.8834343550279027}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(qrels, bm25_runs_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{R@100: 0.18083872999666104,\n",
       " nDCG@20: 0.23678173299404812,\n",
       " RBP(rel=1): 0.34433565736077315,\n",
       " AP: 0.25477962239826385,\n",
       " R@1000: 0.88309759916862}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(qrels, bm25_runs_title_and_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(df_merged):\n",
    "    # For each query, apply TF-IDF\n",
    "    grouped = df_merged.groupby(\"query_id\")\n",
    "\n",
    "    results = []\n",
    "    for query_id, group in tqdm(grouped):\n",
    "        query_title = group[\"query_title_translated\"].iloc[0] \n",
    "        docs_title = group[\"document_title\"].tolist()  \n",
    "        docs_content = group[\"content\"].tolist() \n",
    "        \n",
    "        # Preprocess titles and content\n",
    "        query_tokens = preprocess(query_title)\n",
    "        doc_title_tokens = [preprocess(doc) for doc in docs_title]\n",
    "        doc_content_tokens = [preprocess(doc) for doc in docs_content]\n",
    "        \n",
    "        # TF-IDF calculation for document titles\n",
    "        vectorizer_title = TfidfVectorizer()\n",
    "        tfidf_title = vectorizer_title.fit_transform(docs_title)\n",
    "        query_tfidf_title = vectorizer_title.transform([query_title])\n",
    "        scores_title = cosine_similarity(query_tfidf_title, tfidf_title).flatten()\n",
    "        \n",
    "        # TF-IDF calculation for document content\n",
    "        vectorizer_content = TfidfVectorizer()\n",
    "        tfidf_content = vectorizer_content.fit_transform(docs_content)\n",
    "        query_tfidf_content = vectorizer_content.transform([query_title])\n",
    "        scores_content = cosine_similarity(query_tfidf_content, tfidf_content).flatten()\n",
    "        \n",
    "        # TF-IDF calculation for concatenated title and content\n",
    "        docs_title_and_content = [title + \" \" + content for title, content in zip(docs_title, docs_content)]\n",
    "        vectorizer_title_and_content = TfidfVectorizer()\n",
    "        tfidf_title_and_content = vectorizer_title_and_content.fit_transform(docs_title_and_content)\n",
    "        query_tfidf_title_and_content = vectorizer_title_and_content.transform([query_title])\n",
    "        scores_title_and_content = cosine_similarity(query_tfidf_title_and_content, tfidf_title_and_content).flatten()\n",
    "        \n",
    "        # Append results for each document\n",
    "        for doc_id, score_title, score_content, score_title_and_content, doc_title in zip(group[\"doc_id\"], scores_title, scores_content, scores_title_and_content, docs_title):\n",
    "            results.append({\n",
    "                \"query_id\": query_id,\n",
    "                \"doc_id\": doc_id,\n",
    "                \"document_title\": doc_title,\n",
    "                \"score_title\": score_title,\n",
    "                \"score_content\": score_content,\n",
    "                \"score_title_and_content\": score_title_and_content\n",
    "            })\n",
    "\n",
    "    # Create DataFrame with TF-IDF scores\n",
    "    tfidf_results = pd.DataFrame(results)\n",
    "\n",
    "    # Merge TF-IDF results with original dataframe\n",
    "    final_df = pd.merge(df_merged, tfidf_results, on=[\"query_id\", \"doc_id\"])\n",
    "\n",
    "    # Sort documents within each query by score_title descending and query_id \n",
    "    sorted_final_df = final_df.sort_values(by=[\"query_id\", \"score_title\"], ascending=[True, False])\n",
    "\n",
    "    return sorted_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6886be63e5f84caabc08a80f834d329c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf_df = tfidf(df_merged)\n",
    "\n",
    "tfidf_runs_title = sorted(zip(tfidf_df['query_id'], tfidf_df['doc_id'], tfidf_df['score_title']), key=lambda x: (x[0], -x[2]))\n",
    "tfidf_runs_content = sorted(zip(tfidf_df['query_id'], tfidf_df['doc_id'], tfidf_df['score_content']), key=lambda x: (x[0], -x[2]))\n",
    "tfidf_runs_title_and_content= sorted(zip(tfidf_df['query_id'], tfidf_df['doc_id'], tfidf_df['score_title_and_content']), key=lambda x: (x[0], -x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{R@100: 0.1533779267713137,\n",
       " nDCG@20: 0.20222656522819074,\n",
       " RBP(rel=1): 0.2849204994203492,\n",
       " AP: 0.22690498394177694,\n",
       " R@1000: 0.8816415525072032}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(qrels, tfidf_runs_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{R@100: 0.18640436045800213,\n",
       " nDCG@20: 0.21617987974336925,\n",
       " RBP(rel=1): 0.30768511978516333,\n",
       " AP: 0.25478898588165183,\n",
       " R@1000: 0.8853175971573662}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(qrels, tfidf_runs_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{R@100: 0.18638355509462465,\n",
       " nDCG@20: 0.22151818944627474,\n",
       " RBP(rel=1): 0.3146175197853463,\n",
       " AP: 0.25490511606903354,\n",
       " R@1000: 0.8849928452878565}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(qrels, tfidf_runs_title_and_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
