{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import ir_datasets\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import ir_measures\n",
    "\n",
    "from ir_measures import nDCG, MAP, RBP, Recall, Qrel, ScoredDoc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation function \n",
    "def evaluate(qrels, result):\n",
    "    qrels = [\n",
    "        Qrel(query_id=query_id, doc_id=doc_id, relevance=relevance)\n",
    "        for query_id, doc_id, relevance in qrels   \n",
    "    ]\n",
    "\n",
    "    runs = [\n",
    "        ScoredDoc(query_id=query_id, doc_id=doc_id, score=score)\n",
    "        for query_id, doc_id, score in result\n",
    "    ]\n",
    "    scores = ir_measures.calc_aggregate([nDCG@20, MAP, RBP(rel=1), Recall@100, Recall@1000], qrels, runs)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923f08d371b24033b5da67350e7e1ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding queries:   0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('data/multi-subset.pkl', 'rb') as file:\n",
    "    document_subset = pickle.load(file)\n",
    "\n",
    "dataset = ir_datasets.load(\"neuclir/1/multi/trec-2023\")\n",
    "dataset\n",
    "english_queries = [(query.query_id, query.title) for query in dataset.queries_iter()]\n",
    "qrels = [(qrel.query_id, qrel.doc_id, qrel.relevance) for qrel in dataset.qrels_iter()]\n",
    "\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "query_embeddings = [\n",
    "    (query[0], model.encode(query[1], convert_to_tensor=True)) \n",
    "    for query in tqdm(english_queries, desc=\"Encoding queries\")\n",
    "]\n",
    "\n",
    "with open('document_embeddings.pkl', 'rb') as file:\n",
    "    document_embeddings = pickle.load(file)\n",
    "\n",
    "with open('data/multi-subset.pkl', 'rb') as file:\n",
    "    multi_subset = pickle.load(file)\n",
    "\n",
    "multi_ids = [item[0] for item in multi_subset]\n",
    "document_embeddings = list(zip(multi_ids, document_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_for_id(qrels, document_embeddings, target_id):\n",
    "    # Create a dictionary from document_embeddings for fast lookup\n",
    "    doc_embeddings_dict = {doc_id: emb for doc_id, emb in document_embeddings}\n",
    "\n",
    "    # Iterate through qrels to find the target id and return its embedding\n",
    "    for _, doc_id, _ in qrels:\n",
    "        if doc_id == target_id:\n",
    "            return doc_embeddings_dict.get(doc_id, None)\n",
    "        \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66d46430ee24181a8f008cd12e32506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4fe9b530554435a6ae44e710861d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a515b15c2fc40beb82a980212ba22b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/862 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eef5e4ad8874a7ea7ccc0c52f56c7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3811361472a466fb5ddac018737c998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/967 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9ce2ddab6e46a5bf43a51a744eda31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd7f15cade044c9ae936d1af6c2d04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1523 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b173aa0c10247efa952151ca38da86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5456db72fd4e2d9e536eea9525a85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1019 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125f4594fa79467a8b9fe230e1c07941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e9608cad764e42b566a42ec5984df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_subset = []\n",
    "document_embedding_subset = [] \n",
    "labels_subset = [] \n",
    "count = 0\n",
    "for qrel_number in tqdm(range(200, 210)):\n",
    "    filtered_qrels = [tup for tup in qrels if tup[0] == str(qrel_number)]\n",
    "  \n",
    "    for qrel in tqdm(filtered_qrels): \n",
    "        target_id = qrel[1]\n",
    "        embedding = get_embedding_for_id(qrels, document_embeddings, target_id)\n",
    "        document_embedding_subset.append(embedding)\n",
    "        labels_subset.append(qrel[2])\n",
    "    \n",
    "    training_subset_current_iteration = [torch.cat((tensor, query_embeddings[count][1]), dim=0) for tensor in document_embedding_subset]\n",
    "    training_subset.extend(training_subset_current_iteration)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DocumentQueryDataset(Dataset):\n",
    "    def __init__(self, feature_embeddings, relevance_scores):\n",
    "        self.feature_embeddings = feature_embeddings\n",
    "        self.relevance_scores = relevance_scores\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.relevance_scores)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature_embeddings = torch.tensor(self.feature_embeddings[idx], dtype=torch.float32)\n",
    "        relevance_score = torch.tensor(self.relevance_scores[idx], dtype=torch.float32)\n",
    "        return feature_embeddings, relevance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming doc_embeddings, query_embeddings, and relevance_scores are numpy arrays or lists\n",
    "dataset = DocumentQueryDataset(training_subset, labels_subset)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPModel, self).__init__()\n",
    "        # Input layer is 2 * embedding_size\n",
    "        self.input_size = 768\n",
    "        \n",
    "        # Define the hidden layers\n",
    "        self.hidden1 = nn.Linear(self.input_size, 768)\n",
    "        self.hidden2 = nn.Linear(768, 384)\n",
    "        self.output = nn.Linear(384, 4)  \n",
    "        \n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden1(x))\n",
    "        x = self.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x  # Raw logits for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = MLPModel()  # Set embedding size based on your embeddings\n",
    "criterion = nn.CrossEntropyLoss()  # Cross entropy for multi-class classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I555270\\AppData\\Local\\Temp\\ipykernel_25836\\2772734791.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  feature_embeddings = torch.tensor(self.feature_embeddings[idx], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.3241698741912842\n",
      "Epoch 2/5, Loss: 1.2908841371536255\n",
      "Epoch 3/5, Loss: 0.7200946807861328\n",
      "Epoch 4/5, Loss: 0.4602888822555542\n",
      "Epoch 5/5, Loss: 0.5500671863555908\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for data, target in dataloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        target = target.long()\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('7707eaec-e3a6-422a-9e49-68ef7d2baaec',\n",
       " tensor([ 0.2471, -0.0563,  0.1989,  0.2372,  0.2023,  0.0907,  0.1063,  0.0344,\n",
       "          0.0772,  0.0111,  0.1059,  0.0678, -0.0716,  0.1183,  0.2134, -0.0463,\n",
       "          0.1280, -0.1676, -0.3580,  0.2306, -0.2797, -0.0795,  0.1890,  0.1065,\n",
       "         -0.1021,  0.0766, -0.1166, -0.0851, -0.1898,  0.0535,  0.0759, -0.0718,\n",
       "          0.0698, -0.0335, -0.1357,  0.0945, -0.0415,  0.0902, -0.1679, -0.0291,\n",
       "         -0.0273, -0.1866,  0.0859, -0.0446, -0.1004,  0.1884,  0.0150,  0.0557,\n",
       "         -0.0983, -0.0696, -0.0465,  0.0185,  0.1249,  0.0862,  0.0469,  0.2441,\n",
       "         -0.0667, -0.0874, -0.1384,  0.1545,  0.1402, -0.0100,  0.0443,  0.2315,\n",
       "          0.1856, -0.0649, -0.1911, -0.0896, -0.0506, -0.1312,  0.1476,  0.0244,\n",
       "         -0.0703, -0.0612,  0.0666, -0.0420, -0.1119, -0.0168, -0.1232, -0.3195,\n",
       "          0.0789, -0.0761,  0.0936,  0.0570, -0.0341, -0.0104, -0.0372, -0.0689,\n",
       "         -0.2534,  0.1144, -0.0940,  0.0567,  0.1318, -0.0337,  0.1432,  0.0315,\n",
       "         -0.2527, -0.0891, -0.0283,  0.2968, -0.1605,  0.0890, -0.0095,  0.1746,\n",
       "          0.1494, -0.1516, -0.0515, -0.2632,  0.0388,  0.1726, -0.0694, -0.0208,\n",
       "         -0.0005, -0.1124, -0.0094, -0.0770, -0.0082,  0.0585,  0.1672, -0.0466,\n",
       "          0.0276, -0.3024, -0.0004, -0.0149,  0.1190, -0.1586, -0.0780, -0.1787,\n",
       "          0.1142, -0.1564,  0.3108,  0.1807,  0.1660,  0.0116, -0.1639, -0.1462,\n",
       "          0.2417,  0.0016,  0.0862,  0.1793,  0.0947,  0.2439,  0.0314, -0.0739,\n",
       "         -0.0931,  0.1546, -0.0379, -0.1180,  0.0119, -0.0809, -0.0423,  0.1124,\n",
       "         -0.0270,  0.1444,  0.0213,  0.0460, -0.0223, -0.1111, -0.2201,  0.1073,\n",
       "          0.1392, -0.1267,  0.0168, -0.1536, -0.0142, -0.0110, -0.0743, -0.2872,\n",
       "          0.1526,  0.0902, -0.0838, -0.0044, -0.0307,  0.0642, -0.0294, -0.1316,\n",
       "         -0.2268,  0.2422,  0.0773, -0.1292,  0.3018, -0.1416, -0.1860, -0.1459,\n",
       "          0.0557, -0.1223, -0.1663, -0.1175,  0.0212,  0.1652,  0.1317, -0.1369,\n",
       "          0.2274,  0.1565, -0.1105,  0.1728,  0.1110,  0.1447, -0.2377,  0.2028,\n",
       "         -0.1494, -0.0872,  0.1324,  0.0133, -0.2575, -0.2142,  0.0836,  0.1269,\n",
       "          0.1848,  0.0405, -0.0268,  0.0749, -0.0216,  0.0535, -0.0056, -0.1248,\n",
       "         -0.3218,  0.1755, -0.0560,  0.1818,  0.0994,  0.0255, -0.0040, -0.1513,\n",
       "         -0.0314, -0.0039, -0.0661, -0.1119,  0.0062,  0.0500,  0.1124,  0.1337,\n",
       "          0.0395,  0.1824, -0.1470, -0.2221, -0.1057,  0.0670,  0.0270,  0.1336,\n",
       "         -0.1322, -0.1457, -0.1660,  0.0809, -0.0099,  0.0606, -0.0318,  0.1025,\n",
       "         -0.0535,  0.2485,  0.2614, -0.1376, -0.0437, -0.0956, -0.1183,  0.0828,\n",
       "         -0.0827, -0.1303, -0.0778,  0.2319, -0.1750, -0.0474,  0.0700, -0.0816,\n",
       "          0.1382,  0.0195, -0.1615, -0.0789,  0.0631,  0.1428, -0.0578, -0.0236,\n",
       "         -0.1302, -0.0609,  0.1609, -0.0905, -0.0896, -0.1028,  0.2140, -0.0809,\n",
       "          0.0251, -0.2674,  0.0819, -0.0087, -0.0458, -0.0732, -0.2529,  0.1098,\n",
       "          0.0371, -0.0408, -0.0599,  0.0756,  0.1667,  0.0639, -0.0555,  0.0604,\n",
       "          0.0566, -0.0491,  0.0307,  0.1494,  0.1005, -0.0542, -0.0973, -0.0554,\n",
       "         -0.0813, -0.2599,  0.1956, -0.0589, -0.1157,  0.0939, -0.2594, -0.1528,\n",
       "         -0.0852,  0.0793, -0.0250,  0.0319, -0.1417,  0.1207, -0.0120, -0.1595,\n",
       "          0.2078, -0.0951,  0.2032, -0.0144,  0.0398,  0.1407,  0.0568,  0.1068,\n",
       "         -0.1171,  0.0745, -0.1565,  0.0815,  0.0359,  0.0507,  0.1148, -0.0596,\n",
       "         -0.0551,  0.0468,  0.0641,  0.1165,  0.1418,  0.0602, -0.0744,  0.1506,\n",
       "         -0.0206,  0.0800, -0.1959, -0.2383, -0.0845,  0.1113,  0.1459,  0.0926,\n",
       "         -0.1335,  0.0185,  0.0904, -0.2112, -0.0522, -0.1357,  0.0595, -0.0617,\n",
       "         -0.0045,  0.1508,  0.0912,  0.1504, -0.0415, -0.1158,  0.0007, -0.1532,\n",
       "         -0.0094, -0.0303, -0.1074,  0.0476,  0.0546,  0.1392,  0.0179,  0.0234,\n",
       "          0.0222,  0.2343, -0.0943, -0.1319,  0.2309,  0.2505, -0.2134, -0.0206]))"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a36612de014cefb0187ccbaf42cb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_subset = []\n",
    "testing_document_embedding_subset = [] \n",
    "testing_labels_subset = [] \n",
    "document_ids = []\n",
    "query_id = []\n",
    "\n",
    "count = 0\n",
    "for qrel_number in tqdm(range(200, 270)):\n",
    "    filtered_qrels = [tup for tup in qrels if tup[0] == str(qrel_number)]\n",
    "  \n",
    "    for qrel in filtered_qrels: \n",
    "        target_id = qrel[1]\n",
    "        embedding = get_embedding_for_id(qrels, document_embeddings, target_id)\n",
    "        testing_document_embedding_subset.append(embedding)\n",
    "        document_ids.append(str(200+ count))\n",
    "        testing_labels_subset.append(qrel[2])\n",
    "        query_id.append(target_id)\n",
    "    \n",
    "    testing_subset_current_iteration = [torch.cat((tensor, query_embeddings[count][1]), dim=0) for tensor in testing_document_embedding_subset]\n",
    "    testing_subset.extend(training_subset_current_iteration)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testing_subset.pkl', 'wb') as file:\n",
    "    # Serialize the list and save it to the file\n",
    "    pickle.dump(testing_subset, file)\n",
    "\n",
    "with open('labels_subset.pkl', 'wb') as file:\n",
    "    # Serialize the list and save it to the file\n",
    "    pickle.dump(labels_subset, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "testing_subset_tensor = torch.stack(testing_subset)\n",
    "# Ensure no gradients are computed for inference\n",
    "with torch.no_grad():\n",
    "    # Pass data through the model\n",
    "    predictions = model(testing_subset_tensor)\n",
    "    \n",
    "    # For classification, get the predicted class\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)  # Shape: [batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79934"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "887320"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = list(zip(document_ids, query_id, predicted_classes.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "scores_sorted = []\n",
    "for key, group in groupby(sorted(scores, key=lambda x: x[0]), key=lambda x: x[0]):\n",
    "    # Sort each group by the third item\n",
    "    scores_sorted.extend(sorted(group, key=lambda x: x[2], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{AP: 0.17663493184716525,\n",
       " R@1000: 0.8140258447147039,\n",
       " RBP(rel=1): 0.1955172311579157,\n",
       " R@100: 0.0984033707842195,\n",
       " nDCG@20: 0.11625619697869208}"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(qrels, scores_sorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
